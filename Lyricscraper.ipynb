{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping lyrics from Genius.com\n",
    "\n",
    "Using libraries requests and BeautifulSoup, the code is used to scrape the lyrics of one or multiple songs from the website genius.com\n",
    "\n",
    "Next, the data can be used to create charts that, for example, define the amount of times a specific word is said."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# including libraries for web scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "# including a library to convert datetime format\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a dict to store the title, lyrics and comments on the song\n",
    "\n",
    "song = {}\n",
    "song[\"Artist\"] = []\n",
    "song[\"Title\"] = []\n",
    "song[\"Lyrics\"] = []\n",
    "song[\"Release Date\"] = []\n",
    "song[\"Album\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function that retrieves a song's information\n",
    "\n",
    "def get_song(song_artist, song_title):\n",
    "    if song_artist[-1] == ' ':\n",
    "        song_artist = song_artist[0:-1]\n",
    "    if song_title[-1] == ' ':\n",
    "        song_title = song_title[0:-1]\n",
    "    try:\n",
    "        song_url = \"https://genius.com/{}-{}-lyrics\".format(re.sub(r'\\W+', ' ', song_artist).replace(' ', '-'), \n",
    "                                                            re.sub(r'\\W+', ' ', song_title).replace(' ', '-'))\n",
    "        res = requests.get(song_url)\n",
    "        soup = bs(res.content, 'html.parser')\n",
    "\n",
    "        # extracting the artist, title and release date\n",
    "        for song_title in soup.findAll('title'):\n",
    "            song_title = song_title.text.strip()\n",
    "        song[\"Artist\"].append(song_title.split(u\"\\u2013\")[0].encode('ascii', 'replace').replace(\"?\", ' '))\n",
    "        song[\"Title\"].append(song_title.split(u\"\\u2013\")[1].split(\"Lyrics\")[0].encode('ascii', 'replace').replace(\"?\", ' '))\n",
    "\n",
    "        # extracting the lyrics\n",
    "        for div in soup.findAll('div', attrs = {'class': 'lyrics'}):\n",
    "            song[\"Lyrics\"].append(div.text.strip().split(\"\\n\"))\n",
    "\n",
    "        # extracting the release date\n",
    "        for span in soup.findAll('span', attrs = {'class': 'metadata_unit-info metadata_unit-info--text_only'}):\n",
    "            try:\n",
    "                song[\"Release Date\"] = datetime.datetime.strftime(datetime.datetime.strptime(str(span.text.strip()), \"%B %d, %Y\"), \n",
    "                                                                  \"%Y-%m-%d\")\n",
    "            except:\n",
    "                next\n",
    "\n",
    "        # extracting the album\n",
    "        for a in soup.findAll('a', attrs = {'class': 'song_album-info-title'}):\n",
    "            song[\"Album\"].append(a.text.strip().encode('ascii', 'replace').replace(\"?\", ' '))\n",
    "    except:\n",
    "        print \"url {} not found\".format(song_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_album(album_artist, album_title): \n",
    "    album_url = \"https://genius.com/albums/{}/{}\".format(album_artist.replace(\" \", \"-\"), album_title.replace(\" \", \"-\"))\n",
    "    res = requests.get(album_url)\n",
    "    soup = bs(res.content, \"html.parser\")\n",
    "    album_songs = []\n",
    "    for div in soup.findAll('h3', attrs = {'class': 'chart_row-content-title'}):\n",
    "            album_songs.append(str(div.text.strip().encode('ascii', 'replace').replace(\"?\", ' ').split(\"\\n\")[0].split(\"(\")[0]))\n",
    "            #print div.text.strip().split(\"\\n\")[0]\n",
    "            #print div\n",
    "    return album_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seperating all the words in the song lyrics in a seperate list. Also includes notations about who sings the song, \n",
    "# and what part of the song it is.\n",
    "song_nr = 0\n",
    "wordlist = []\n",
    "for line in song[\"Lyrics\"][song_nr]:\n",
    "    for word in line.split():\n",
    "        wordlist.append(re.sub(r'\\W+', '', word).lower())  # removing non-alphanumerical characters and making it all lowercase\n",
    "\n",
    "wordframe = pd.DataFrame(columns = [\"word\", \"count\"])\n",
    "\n",
    "for word in np.unique(wordlist):\n",
    "    wordframe = wordframe.append(pd.DataFrame([[word, wordlist.count(word)]], columns = [\"word\", \"count\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
